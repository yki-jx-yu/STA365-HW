{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b970618",
   "metadata": {},
   "source": [
    "### 1. Describe how the posterior predictive distribution is created for mixture models\n",
    "\n",
    "For mixture models, the posterior predictive distribution is created by integrating out the uncertainty about the parameters of the model, given the observed data, to make predictions for new data points.\n",
    "\n",
    "Firstly, define a probabilistic model, assuming that the observed data is generated from a mixture of several probability distributions, each corresponding to a different cluster. Secondly, use Bayesian inferences to estimate the posterior distribution of the model parameters given the observed data. This can be done by calculating the posterior distribution using Bayes' theorem, which incorporates the prior beliefs about the parameters and the likelihood of the observed data given the parameters. Once the posterior distribution is obtained, samples are drawn from it using MCMC. Finally, to make predictions for new data points, the model parameters are sampled from the posterior distribution, and then the predictive distribution is calculated based on these sampled parameters.\n",
    "\n",
    "\n",
    "### 2. Describe how the posterior predictive distribution is created in general\n",
    "\n",
    "Similar to the previous question but now including mixture models but not limited to them.\n",
    "\n",
    "Firstly, define a probabilistic model that describes the relationship between the observed data and the unknown parameters. Then, use Bayesian inferences to estimate the posterior distribution of the parameters given the observed data, combining prior beliefs about the parameters with the likelihood of the data given the parameters. After that, sample from the posterior distribution of the parameters using MCMC. Given new input data, sample from the posterior distribution of the parameters and use them to generate predictions for the new data points.\n",
    "\n",
    "### 3. Describe how, if you were doing a regression of $y$ on $X$ but $X$ had some missing values, you could perform a Bayesian analysis without throwing away the rows with missing values in $X$\n",
    "\n",
    "By treating the missing values as latent variables and inferring them jointly with the model parameters, we can incorporate the uncertainty about the missing values into the analysis and make informed predictions without discarding incomplete rows from the dataset. However, it's crucial to be mindful of the MCAR assumption and to assess the robustness of the results to potential violations of this assumption."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
